## Knowledge Check

Test your understanding of EU AI Act transparency requirements:

1. **Which components are required in a high-risk AI system architecture?**  
   a) Model versioning and A/B testing framework  
   b) Explainability services, audit logging, and human oversight  
   c) Microservice architecture with Kubernetes orchestration  
   d) Public API endpoints for all model functionality  

2. **What must be stored in audit trails for high-risk systems?**  
   a) Complete source code for all models  
   b) System uptime and performance metrics  
   c) Input data, output decisions, and explanation metadata  
   d) Team member information who developed the model  

3. **Which statement about explainability is correct?**  
   a) Only black-box models require explanations  
   b) You must use SHAP values for all explanations  
   c) Both technical and non-technical explanations are required for high-risk systems  
   d) Feature importance is only required for computer vision models  

4. **What is a required architectural element for human oversight?**  
   a) Verbal approval process documented manually  
   b) Technical mechanisms for reviewing and overriding AI decisions  
   c) Cross-functional team structure for model deployment  
   d) Weekly human review of all decisions  

5. **Which statement about transparency implementation is true?**  
   a) The EU AI Act requires REST APIs for all transparency interfaces  
   b) The regulation specifies exact storage duration requirements for all data types  
   c) The regulation requires what must be achieved, but implementation details are flexible  
   d) All high-risk systems must use blockchain for immutable audit trails  
